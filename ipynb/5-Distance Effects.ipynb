{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect size extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [last notebook], we calculated emperical and distribution-based power for five types of statistical tests:\n",
    "* One Sample T test\n",
    "* Independent Sample t test \n",
    "* One way ANOVA, 3 groups\n",
    "* One way ANOVA, 8 groups\n",
    "* Linear correlation\n",
    "\n",
    "We will now evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import scipy\n",
    "# import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import effects as eff\n",
    "import plot as plot\n",
    "\n",
    "% matplotlib inline\n",
    "sn.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rounds = 100\n",
    "alpha = 0.05\n",
    "counts = np.arange(5, 100, 10)\n",
    "colormap = 'Spectral'\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_location = './simulations'\n",
    "if not os.path.exists(sim_location):\n",
    "    raise ValueError('The power simulations do not exist.'\n",
    "                     'Please go back to notebooks 2 and 3 and'\n",
    "                     'calculate power.'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = sn.color_palette(colormap, n_colors=len(counts))\n",
    "check_color = {count: colors[i] for i, count in enumerate(counts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests = ['permanova', 'mantel']\n",
    "# tests = ['ttest_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extrapolated = ['f_power', 't_power', 'z_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distributions = {'permanova': {'clean_name': 'PERMANOVA',\n",
    "                               'num_groups': 2,\n",
    "                               'input_dir': './simulations/power/permanova/',\n",
    "                               'return_fp': './simulations/extrapolation/permanova.txt'\n",
    "                               },\n",
    "                 'mantel': {'clean_name': 'Mantel',\n",
    "                            'num_groups': 2,\n",
    "                            'input_dir': './simulations/power/mantel/',\n",
    "                            'return_fp': './simulations/extrapolation/mantel.txt'\n",
    "                            },\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_dir = './simulations/extrapolation/'\n",
    "if not os.path.exists(return_dir):\n",
    "    os.makedirs(return_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by calculating the emperical and extrapolated effect sizes for the parametric tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_name in tests:\n",
    "    power_dir = distributions[test_name]['input_dir']\n",
    "    num_groups = distributions[test_name]['num_groups']\n",
    "    return_fp = distributions[test_name]['return_fp']\n",
    "    \n",
    "    if not os.path.exists(power_dir):\n",
    "        raise ValueError('%s does not exist' % power_dir)\n",
    "        \n",
    "    summaries = []\n",
    "     # Loops through the rounds\n",
    "    for i in range(5):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for test_name in tests:\n",
    "    power_dir = distributions[test_name]['input_dir']\n",
    "    num_groups = distributions[test_name]['num_groups']\n",
    "    return_fp = distributions[test_name]['return_fp']\n",
    "    \n",
    "    if not os.path.exists(power_dir):\n",
    "        raise ValueError('%s does not exist' % power_dir)\n",
    "        \n",
    "    summaries = []\n",
    "    \n",
    "    # Loops through the rounds\n",
    "    for i in range(num_rounds):\n",
    "        # Loads through the power simulation for the round\n",
    "        power_fp = os.path.join(power_dir, 'simulation_%i.p' % i)\n",
    "        \n",
    "        with open(power_fp, 'rb') as f_:\n",
    "            sim = pickle.load(f_)\n",
    "        \n",
    "        # Pulls the previously calculated power values\n",
    "        counts = sim['counts']\n",
    "        emperical = sim['emperical_power']\n",
    "        empr_shape = emperical.shape\n",
    "        z_effect = eff.z_effect(counts, emperical, alpha=0.05)\n",
    "        t_effect = eff.t_effect(counts, emperical, alpha=0.05)\n",
    "        f_effect = eff.f_effect(counts, emperical, groups=3, alpha=0.05)\n",
    "        num_obs = (empr_shape[0] * empr_shape[1])\n",
    "        run_summary = pd.DataFrame({\n",
    "                    'counts': np.hstack([counts] * empr_shape[0]),\n",
    "                    'emperical_power': np.hstack(emperical),\n",
    "                    'sim_pos': np.hstack([np.arange(empr_shape[1]) + (i + 1) * 10 \n",
    "                                          for i in range(empr_shape[0])]),\n",
    "                    'z_effect': np.hstack(z_effect),\n",
    "                    't_effect': np.hstack(t_effect),\n",
    "                    'f_effect': np.hstack(f_effect),\n",
    "                    'z_power': np.hstack([eff.z_power(counts, np.nanmean(z_effect))]\n",
    "                                         * empr_shape[0]),\n",
    "                    't_power': np.hstack([eff.t_power(counts, np.nanmean(t_effect))]\n",
    "                                         * empr_shape[0]),\n",
    "                    'f_power': np.hstack([eff.f_power(counts, np.nanmean(f_effect), groups=num_groups)]\n",
    "                                         * empr_shape[0]),\n",
    "                    })\n",
    "        run_summary['color'] = run_summary['counts'].apply(lambda x: check_color[x])\n",
    "        run_summary['test'] = test_name\n",
    "        run_summary['clean_name'] = distributions[test_name]['clean_name']\n",
    "        run_summary['simulation'] = i\n",
    "        run_summary['fit_f-mean'] = np.nanmean(f_effect)\n",
    "        run_summary['fit_f-std'] = np.nanstd(f_effect)\n",
    "        run_summary['fit_f-count'] = np.sum(np.isnan(f_effect) == False) / num_obs\n",
    "        run_summary['fit_t-mean'] = np.nanmean(t_effect)\n",
    "        run_summary['fit_t-std'] = np.nanstd(t_effect)\n",
    "        run_summary['fit_t-count'] = np.sum(np.isnan(t_effect) == False) / num_obs\n",
    "        run_summary['fit_z-mean'] = np.nanmean(z_effect)\n",
    "        run_summary['fit_z-std'] = np.nanstd(z_effect)\n",
    "        run_summary['fit_z-count'] = np.sum(np.isnan(z_effect) == False) / num_obs\n",
    "        run_summary['index'] = (run_summary['test'] + '.' +  \n",
    "                                run_summary['simulation'].apply(lambda x: '%i' % x) + '.' +\n",
    "                                run_summary['sim_pos'].apply(lambda x: '%i' % x))\n",
    "        run_summary.set_index('index', inplace=True)\n",
    "        summaries.append(pd.DataFrame(run_summary))\n",
    "    summaries = pd.concat(summaries)\n",
    "    summaries.to_csv(return_fp, sep='\\t')\n",
    "    distributions[test_name]['summary'] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the effect sizes and fits, we find the behavior of the curve \n",
    "\n",
    "Let's also compare the behavior of the emperical power and the fit power curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sets up the figure and axes\n",
    "er_fig, er_axes = plt.subplots(3, 4)\n",
    "er_fig.set_size_inches(8, 6)\n",
    "sn.despine()\n",
    "\n",
    "for ax in er_axes[:, 2:].flatten():\n",
    "    ax.set_visible(False)\n",
    "\n",
    "for idc, test_name in enumerate(tests):\n",
    "    summary = distributions[test_name]['summary']\n",
    "    for metric, ax_reg in zip(*[extrapolated, er_axes.T[idc]]):\n",
    "        plot.gradient_regression(ax=ax_reg, \n",
    "                            x='emperical_power', \n",
    "                            y=metric, \n",
    "                            gradient='color', \n",
    "                            alpha=0.25,\n",
    "                            data=summary\n",
    "                            )\n",
    "        plot.format_regression_axis(ax_reg)\n",
    "        if metric == 'z_power':\n",
    "            ax_reg.set_xticklabels(ax_reg.get_xticks())\n",
    "        if metric == 'f_power':\n",
    "            ax_reg.set_title(distributions[test_name]['clean_name'])\n",
    "        if test_name == tests[0]:\n",
    "            ax_reg.set_yticklabels(ax_reg.get_yticks())\n",
    "            ax_reg.set_ylabel(metric.replace('_', ' ').capitalize())\n",
    "        \n",
    "er_axes[-1][2].set_xlabel('Emperical Power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like both permutative distributions lead to a curves correlation. Some of that behavior may be shaped by the effects at lower and upper power, where the effect size approximation is difficult. So, we'll try recalculating the effect sizes and power exlcuding power less than 0.1, or power greater than 0.95 in the effect size calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_series_f(x):\n",
    "    pwr = eff.f_power(np.array([x['counts']]), np.array([x['fit_f-mean']]))\n",
    "    return pwr[0]\n",
    "def calc_series_t(x):\n",
    "    pwr = eff.t_power(np.array([x['counts']]), np.array([x['fit_t-mean']]))\n",
    "    return pwr[0]\n",
    "def calc_series_z(x):\n",
    "    pwr = eff.z_power(np.array([x['counts']]), np.array([x['fit_t-mean']]))\n",
    "    return pwr[0]\n",
    "\n",
    "def calc_modified_effect(drop_index, summary):\n",
    "    \"\"\"...\"\"\"\n",
    "    copy_cols = ['emperical_power', 'counts', 'color', \n",
    "                 'clean_name', 'simulation', 'sim_pos', 'test',\n",
    "                 'f_effect', 't_effect', 'z_effect']\n",
    "    summary_mod = copy.deepcopy(summary[copy_cols])\n",
    "    summary_mod.loc[drop_index,  ['f_effect', 't_effect', 'z_effect']] = np.nan\n",
    "    mean_lookup = summary_mod.groupby('simulation').mean()[['f_effect', 't_effect', 'z_effect']].to_dict()\n",
    "    std_lookup = summary_mod.groupby('simulation').std()[['f_effect', 't_effect', 'z_effect']].to_dict()\n",
    "    \n",
    "    summary_mod['fit_f-mean'] =  summary_mod['simulation'].replace(mean_lookup['f_effect'])\n",
    "    summary_mod['fit_t-mean'] =  summary_mod['simulation'].replace(mean_lookup['t_effect'])\n",
    "    summary_mod['fit_z-mean'] =  summary_mod['simulation'].replace(mean_lookup['z_effect'])\n",
    "    \n",
    "    summary_mod['fit_f_std'] = summary_mod['simulation'].replace(std_lookup['f_effect'])\n",
    "    summary_mod['fit_t_std'] = summary_mod['simulation'].replace(std_lookup['t_effect'])\n",
    "    summary_mod['fit_z_std'] = summary_mod['simulation'].replace(std_lookup['z_effect'])\n",
    "    \n",
    "    summary_mod['f_power'] = summary_mod.apply(calc_series_f, axis=1)\n",
    "    summary_mod['t_power'] = summary_mod.apply(calc_series_t, axis=1)\n",
    "    summary_mod['z_power'] = summary_mod.apply(calc_series_z, axis=1)\n",
    "    \n",
    "    return summary_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idc, test_name in enumerate(['permanova']):\n",
    "    original = distributions[test_name]['summary']\n",
    "    drop_index = ((original['emperical_power'] < 0.1) | \n",
    "                  (original['emperical_power'] > 0.9)\n",
    "                  )\n",
    "    summary = calc_modified_effect(drop_index, original)\n",
    "    for metric, ax_reg in zip(*[extrapolated, er_axes.T[idc + 2]]):\n",
    "        ax_reg.set_visible(True)\n",
    "        plot.gradient_regression(ax=ax_reg, \n",
    "                            x='emperical_power', \n",
    "                            y=metric, \n",
    "                            gradient='color', \n",
    "                            alpha=0.25,\n",
    "                            data=summary\n",
    "                            )\n",
    "        plot.format_regression_axis(ax_reg)\n",
    "        if metric == 'z_power':\n",
    "            ax_reg.set_xticklabels(ax_reg.get_xticks())\n",
    "        if metric == 'f_power':\n",
    "            ax_reg.set_title('%s\\n(limited)' % distributions[test_name]['clean_name'])\n",
    "\n",
    "er_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
